{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeSH-Based Semantic Normalization and Categorization\n",
    "\n",
    "Notebook: MeSH_Keyword_and_Synonym_Matching.ipynb\n",
    "Authors: Elizaveta Popova, Negin Babaiha\n",
    "Institution: University of Bonn, Fraunhofer SCAI\n",
    "Date: 09/04/2025\n",
    "\n",
    "Description:\n",
    "    This notebook processes the MeSH descriptor XML file (desc2025.xml) to support downstream tasks in\n",
    "    semantic triple extraction and evaluation. It includes two major functionalities:\n",
    "\n",
    "    1. Triple Entity Synonym Matching:\n",
    "        - Extracts unique entities from GPT and CBM triples.\n",
    "        - Normalizes and aligns them to MeSH descriptors using synonym lookup.\n",
    "        - Output: \n",
    "            - `mesh_triples_synonyms.json`: entity → preferred MeSH term and synonyms\n",
    "            - `unmatched_triples.json`: entities with no MeSH match\n",
    "\n",
    "    2. Category Keyword Extraction:\n",
    "        - Parses MeSH descriptors to identify terms related to 6 key pathophysiological categories.\n",
    "        - Matches based on keyword heuristics.\n",
    "        - Output: `mesh_category_terms.json` — category → term list.\n",
    "\n",
    "    These outputs are used for normalization, comparison, and evaluation in BioBERT-based triple matching.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH for Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 1574 unique entities from triples.\n",
      "Loaded 30956 descriptors from MeSH.\n",
      "Found MeSH matches (incl. exact COVID overrides) for 437 entities.\n",
      "Still unmatched: 1137 entities.\n"
     ]
    }
   ],
   "source": [
    "# === Map Triple Entities to MeSH Synonyms with COVID Normalization (Exact Match) ===\n",
    "\"\"\"\n",
    "Loads subject/object terms from GPT and CBM triples, normalizes them, and maps them to MeSH descriptors.\n",
    "All COVID-related entities are explicitly normalized to 'covid-19' based on exact string matches only.\n",
    "\n",
    "Outputs:\n",
    "    - mesh_triples_synonyms.json\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import re\n",
    "\n",
    "# === Step 1: Load triples from Excel files ===\n",
    "file_paths = [\n",
    "    \"../data/gold_standard_comparison/Triples_CBM_Gold_Standard.xlsx\",\n",
    "    \"../data/gold_standard_comparison/Triples_GPT_for_comparison.xlsx\"\n",
    "]\n",
    "\n",
    "all_subjects = set()\n",
    "all_objects = set()\n",
    "\n",
    "for path in file_paths:\n",
    "    df = pd.read_excel(path)\n",
    "    if 'Subject' in df.columns and 'Object' in df.columns:\n",
    "        subjects = df['Subject'].dropna().str.lower().str.strip()\n",
    "        objects = df['Object'].dropna().str.lower().str.strip()\n",
    "        all_subjects.update(subjects)\n",
    "        all_objects.update(objects)\n",
    "\n",
    "raw_entities = sorted(all_subjects.union(all_objects))\n",
    "print(f\"Collected {len(raw_entities)} unique entities from triples.\")\n",
    "\n",
    "# === Normalize entities ===\n",
    "def normalize_entity(text):\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "normalized_mapping = {entity: normalize_entity(entity) for entity in raw_entities}\n",
    "normalized_entities = sorted(set(normalized_mapping.values()))\n",
    "\n",
    "# === Step 2: Parse MeSH XML descriptors ===\n",
    "mesh_path = \"../data/MeSh_data/desc2025.xml\"\n",
    "tree = ET.parse(mesh_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "descriptor_synonyms = {}\n",
    "\n",
    "for descriptor in root.findall(\".//DescriptorRecord\"):\n",
    "    descriptor_ui = descriptor.findtext(\"./DescriptorUI\")\n",
    "    descriptor_name = descriptor.findtext(\"./DescriptorName/String\")\n",
    "    if not descriptor_name:\n",
    "        continue\n",
    "    descriptor_name_norm = normalize_entity(descriptor_name)\n",
    "\n",
    "    synonyms = set()\n",
    "    synonyms.add(descriptor_name_norm)\n",
    "\n",
    "    for term in descriptor.findall(\".//TermList/Term/String\"):\n",
    "        if term.text:\n",
    "            synonyms.add(normalize_entity(term.text))\n",
    "\n",
    "    descriptor_synonyms[descriptor_name_norm] = {\n",
    "        \"uid\": descriptor_ui,\n",
    "        \"preferred\": descriptor_name,\n",
    "        \"synonyms\": sorted(synonyms)\n",
    "    }\n",
    "\n",
    "print(f\"Loaded {len(descriptor_synonyms)} descriptors from MeSH.\")\n",
    "\n",
    "# === Step 3: Build reverse synonym lookup ===\n",
    "synonym_lookup = {}\n",
    "for descriptor_data in descriptor_synonyms.values():\n",
    "    for synonym in descriptor_data[\"synonyms\"]:\n",
    "        synonym_lookup[synonym] = descriptor_data\n",
    "\n",
    "# === Step 4: Match entities to MeSH and normalize COVID terms by exact match ===\n",
    "entity_to_mesh = {}\n",
    "unmatched = []\n",
    "\n",
    "# Define COVID override terms (exact match only, all lowercased and normalized)\n",
    "covid_keywords = [\n",
    "    \"covid\", \"covid-19\", \"covid 19\", \"sars cov 2\", \"covid19\",\n",
    "    \"sars-cov-2\", \"sars-cov-2 infection\", \"covid-19 infection\", \"covid-19_infection\", \"neurocovid\",\n",
    "    \"replicated severe acute respiratory syndrome coronavirus 2\", \"sars-cov-2 virus\",\n",
    "    \"severe acute respiratory syndrome coronavirus 2\", \"severe acute respiratory syndrome coronavirus\"\n",
    "]\n",
    "covid_keywords = [normalize_entity(term) for term in covid_keywords]\n",
    "\n",
    "def is_exact_covid_match(text):\n",
    "    return text in covid_keywords\n",
    "\n",
    "for original, normalized in normalized_mapping.items():\n",
    "    if is_exact_covid_match(normalized):\n",
    "        entity_to_mesh[original] = {\n",
    "            \"normalized\": \"covid-19\",\n",
    "            \"uid\": \"COVID\",\n",
    "            \"preferred\": \"COVID-19\",\n",
    "            \"synonyms\": covid_keywords\n",
    "        }\n",
    "    elif normalized in synonym_lookup:\n",
    "        match = synonym_lookup[normalized]\n",
    "        entity_to_mesh[original] = {\n",
    "            \"normalized\": normalized,\n",
    "            \"uid\": match[\"uid\"],\n",
    "            \"preferred\": match[\"preferred\"],\n",
    "            \"synonyms\": match[\"synonyms\"]\n",
    "        }\n",
    "    else:\n",
    "        unmatched.append(original)\n",
    "\n",
    "# === Step 5: Save results ===\n",
    "with open(\"../data/MeSh_data/mesh_triples_synonyms.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(entity_to_mesh, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Found MeSH matches (incl. exact COVID overrides) for {len(entity_to_mesh)} entities.\")\n",
    "print(f\"Still unmatched: {len(unmatched)} entities.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeSH for Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preview: Immune and Inflammatory Response ===\n",
      "- 1, ADP-ribosyl Cyclase\n",
      "- 1, IFN-gamma Receptor\n",
      "- 120a Antigen, CD\n",
      "- 120b Antigen, CD\n",
      "- 12E7 Antigen\n",
      "- 12E7 Protein\n",
      "- 19S Gamma Globulin\n",
      "- 2, C-EBP-Related Protein\n",
      "- 23-C-EBP Protein\n",
      "- 28 kDa Protein, Adipocyte\n",
      "- 293 Cell, HEK\n",
      "- 293 Cells, HEK\n",
      "- 293T Cell\n",
      "- 293T Cells\n",
      "- 4 1BB Receptor\n",
      "- 4 1BB Receptors\n",
      "- 4-1BB Receptor\n",
      "- 4-1BB Receptors\n",
      "- 40-C-EBP Protein\n",
      "- 4F2 Antigen\n",
      "- 4F2 Antigen, Human\n",
      "- 4F2-antigen\n",
      "- 60B8 A Antigen\n",
      "- 60B8 B Antigen\n",
      "- 60B8-A Antigen\n",
      "\n",
      "Extraction complete! Terms saved to: ../data/MeSh_data/mesh_category_terms.json\n"
     ]
    }
   ],
   "source": [
    "# === MeSH-Based Category Keyword Extraction ===\n",
    "\"\"\"\n",
    "Extracts MeSH terms grouped by conceptual categories relevant to COVID-19 and neurodegeneration.\n",
    "Uses predefined seed keywords to identify relevant descriptors.\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Load MeSH descriptor file ===\n",
    "tree = ET.parse('../data/MeSh_data/desc2025.xml')  # Update path if necessary\n",
    "root = tree.getroot()\n",
    "\n",
    "# === Define core category-matching keywords (seeds) ===\n",
    "category_keywords = {\n",
    "    \"Viral Entry and Neuroinvasion\": [\n",
    "        \"neuroinvasion\", \"receptor\", \"ACE2\", \"blood-brain barrier\", \"BBB\", \"virus entry\", \"olfactory\", \n",
    "        \"retrograde transport\", \"endocytosis\", \"direct invasion\", \"cranial nerve\", \"neural pathway\", \n",
    "        \"transcribrial\", \"neurotropic\", \"trans-synaptic\", \"neuronal route\", \"olfactory nerve\", \n",
    "        \"hematogenous\", \"choroid plexus\", \"neuronal transmission\", \"entry into CNS\"\n",
    "    ],\n",
    "    \"Immune and Inflammatory Response\": [\n",
    "        \"immune\", \"cytokine\", \"inflammation\", \"interferon\", \"TNF\", \"IL-6\", \"IL6\", \"cytokine storm\", \n",
    "        \"immune response\", \"inflammatory mediators\", \"macrophage\", \"microglia\", \"neutrophil\", \n",
    "        \"lymphocyte\", \"innate immunity\", \"immune dysregulation\", \"chemokine\", \"T cell\", \"NLRP3\", \n",
    "        \"antibody\", \"immune activation\", \"immune imbalance\", \"immune-mediated\", \"complement\"\n",
    "    ],\n",
    "    \"Neurodegenerative Mechanisms\": [\n",
    "        \"neurodegeneration\", \"protein aggregation\", \"apoptosis\", \"cell death\", \"synaptic loss\", \n",
    "        \"neurotoxicity\", \"oxidative stress\", \"mitochondrial dysfunction\", \"tau\", \"amyloid\", \n",
    "        \"α-synuclein\", \"prion\", \"demyelination\", \"neuron loss\", \"misfolded proteins\", \n",
    "        \"chronic neuronal damage\", \"neurodegenerative\", \"neuroinflammation\"\n",
    "    ],\n",
    "    \"Vascular Effects\": [\n",
    "        \"stroke\", \"thrombosis\", \"vascular\", \"ischemia\", \"coagulation\", \"blood clot\", \"microthrombi\", \n",
    "        \"endothelial\", \"vasculitis\", \"hemorrhage\", \"blood vessel\", \"vascular damage\", \"capillary\", \n",
    "        \"clotting\", \"hypoperfusion\", \"angiopathy\", \"vasculopathy\"\n",
    "    ],\n",
    "    \"Psychological and Neurological Symptoms\": [\n",
    "        \"cognitive\", \"memory\", \"fatigue\", \"depression\", \"anxiety\", \"brain fog\", \"psychiatric\", \n",
    "        \"mood\", \"confusion\", \"neuropsychiatric\", \"emotional\", \"behavioral\", \"neurocognitive\", \n",
    "        \"insomnia\", \"psychosocial\", \"attention\", \"motivation\", \"executive function\", \"suicidality\"\n",
    "    ],\n",
    "    \"Systemic Cross-Organ Effects\": [\n",
    "        \"lungs\", \"liver\", \"kidney\", \"systemic\", \"multi-organ\", \"gastrointestinal\", \"heart\", \n",
    "        \"cardiovascular\", \"endocrine\", \"renal\", \"pancreas\", \"organ failure\", \"liver damage\", \n",
    "        \"pulmonary\", \"myocardial\", \"respiratory\", \"hypoxia\", \"oxygen deprivation\", \"fibrosis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# === Parse MeSH XML and extract matching terms per category ===\n",
    "category_terms = defaultdict(set)\n",
    "\n",
    "for descriptor in root.findall('DescriptorRecord'):\n",
    "    descriptor_name_el = descriptor.find('DescriptorName/String')\n",
    "    if descriptor_name_el is None:\n",
    "        continue\n",
    "\n",
    "    descriptor_name = descriptor_name_el.text\n",
    "    term_elements = descriptor.findall('ConceptList/Concept/TermList/Term/String')\n",
    "    synonyms = [term_el.text for term_el in term_elements if term_el is not None]\n",
    "    all_text = f\"{descriptor_name} \" + ' '.join(synonyms)\n",
    "\n",
    "    for category, keywords in category_keywords.items():\n",
    "        if any(keyword.lower() in all_text.lower() for keyword in keywords):\n",
    "            category_terms[category].update([descriptor_name] + synonyms)\n",
    "\n",
    "# === Convert sets to lists ===\n",
    "for category in category_terms:\n",
    "    category_terms[category] = sorted(list(category_terms[category]))\n",
    "\n",
    "# === Preview sample output ===\n",
    "category_name = \"Immune and Inflammatory Response\"\n",
    "print(f\"=== Preview: {category_name} ===\")\n",
    "for term in category_terms[category_name][:25]:  # Show first 25 terms\n",
    "    print(\"-\", term)\n",
    "\n",
    "# === Export to JSON ===\n",
    "output_path = \"../data/MeSh_data/mesh_category_terms.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(category_terms, f, indent=2)\n",
    "\n",
    "print(f\"\\nExtraction complete! Terms saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
